# **Localized Secure LLM with IPFS â€“ RAG Chatbot**  

## **Overview**  
This project is a **secure, localized Retrieval-Augmented Generation (RAG) chatbot** that integrates **LLMs with document-based Q&A capabilities**. It supports **on-device model inference** and utilizes **IPFS (InterPlanetary File System)** for **decentralized storage**.  

Unlike traditional cloud-based AI solutions, this chatbot **runs locally**, providing **enhanced security, privacy, and accessibility** even in **offline or remote environments**.  

---

## **Key Features**  
âœ… **On-Device LLM Inference** â€“ Uses local models like **Phi-2, Mistral-7B, and Llama** for **fast, secure, and private** responses.  
âœ… **Retrieval-Augmented Generation (RAG)** â€“ Retrieves **document snippets** for **context-aware** answers.  
âœ… **Decentralized Storage with IPFS** â€“ Ensures **tamper-proof, secure storage** without relying on centralized servers.  
âœ… **Efficient Embeddings & FAISS Indexing** â€“ Uses **HuggingFace sentence embeddings** and **FAISS** for **high-speed** semantic search.  
âœ… **Smart Caching with DiskCache** â€“ Reduces redundant LLM calls, improving response speed.  
âœ… **Fully Local & Offline Support** â€“ Can be **deployed in remote areas** without **internet connectivity**.  
âœ… **Interactive UI with Streamlit** â€“ A simple, user-friendly chat interface.  

---

## **How It Works**  

### **1. Secure Document Processing**  
- Users **upload a TXT or PDF document**.  
- The document is **chunked** into smaller sections for **efficient retrieval**.  
- **Sentence embeddings** are generated and stored in a **FAISS index**.  

### **2. Retrieval-Augmented Generation (RAG) Pipeline**  
- When a user **asks a question**, **semantic search** retrieves relevant document chunks.  
- The **retrieved context** is **fed into the LLM** to generate an **accurate** answer.  

### **3. Secure & Localized Response Generation**  
- All processing happens **on-device** for **maximum security**.  
- **Cached results** improve **speed** and **efficiency**.  
- If enabled, documents can be stored in **IPFS** for **decentralized access**.  

---

## **Advantages & Selling Points**  

ğŸ” **100% Private & Secure** â€“ No external API calls; all processing is **done locally**.  
ğŸŒ **Works in Remote Areas** â€“ Can be deployed **without an internet connection**.  
âš¡ **Fast & Efficient** â€“ Uses **FAISS indexing and smart caching** for near-instant retrieval.  
ğŸ› ï¸ **Fully Customizable & Extendable** â€“ Supports **model fine-tuning** and **secure parameter adjustments**.  
ğŸ›¡ï¸ **Tamper-Proof Document Storage** â€“ Uses **IPFS** to prevent unauthorized alterations.  
ğŸš€ **Scalable Multi-LLM Support** â€“ Dynamically switch between **Mistral, Phi-2, Llama**, and more.  
ğŸ”— **Web3 Integration Ready** â€“ Can **integrate with smart contracts** for secure model management.  

---

## **Tech Stack**  

### **Backend**  
- **Python** â€“ Core backend logic  
- **LangChain** â€“ Text processing and embeddings  
- **LlamaCpp** â€“ On-device LLM inference  
- **FAISS** â€“ Vector search for fast document retrieval  
- **HuggingFace Embeddings** â€“ Semantic similarity search  
- **DiskCache** â€“ Persistent response caching  

### **Frontend**  
- **Streamlit** â€“ Interactive chatbot UI  

### **Storage & Security**  
- **IPFS** â€“ Decentralized document storage  
- **Tempfile & OS** â€“ Secure temporary file handling  
- **Pickle & FAISS Storage** â€“ Local index persistence  

---

## **Future Enhancements**  

ğŸš€ **Multi-LLM Support** â€“ Dynamically switch between models like **Mistral, Phi-2, or Llama**.  
ğŸ” **End-to-End Encryption** â€“ Secure document retrieval & storage.  
ğŸŒ **Web3 Integration** â€“ Use **smart contracts for model ownership tracking**.  
ğŸ“ˆ **Advanced Hybrid Retrieval** â€“ Combining **BM25 + embeddings** for better context matching.  

---

## **Contributors**  
**Debayan Ghosh** 
**Soumyadeep Basak ** 
**Shubham Sahu** 
---

This project ensures **full privacy, security, and offline functionality** by running **LLMs locally** and storing documents in **a decentralized manner using IPFS.** ğŸš€  
